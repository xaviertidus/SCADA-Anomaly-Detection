{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f57b84",
   "metadata": {},
   "source": [
    "# SCADA Anomaly Detection Analysis\n",
    "\n",
    "IMPORTANT NOTICE: If you use, modify, or build upon this code, please credit:\n",
    "- The original Git repository: https://github.com/xaviertidus/SCADA-Anomaly-Detection\n",
    "- The paper authors: Shirazi et al. (2016). \"Evaluation of Anomaly Detection Techniques for SCADA Communication Resilience\".\n",
    "\n",
    "This notebook replicates anomaly detection from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dcfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    data, meta = arff.loadarff('IanArffDataset.arff')\n",
    "    df = pd.DataFrame(data)\n",
    "except:\n",
    "    df = pd.read_csv('IanRawDataset.txt', sep=',', na_values='?')\n",
    "\n",
    "# Decode if ARFF\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.decode('utf-8')\n",
    "\n",
    "# Features and binary labels\n",
    "features = df.drop(['binary result', 'categorized result', 'specific result', 'time'], axis=1, errors='ignore')\n",
    "labels = df['binary result'].apply(lambda x: 1 if x == \"'1'\" else 0)\n",
    "\n",
    "# Impute missing\n",
    "numerical_cols = features.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = features.select_dtypes(exclude=[np.number]).columns\n",
    "features[numerical_cols] = features[numerical_cols].fillna(features[numerical_cols].mean())\n",
    "if not categorical_cols.empty:\n",
    "    features[categorical_cols] = features[categorical_cols].fillna(features[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Normalize numerical\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features[numerical_cols])\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_pca, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Data preprocessed. Train shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# G-mean helper\n",
    "def g_mean(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "# Train models\n",
    "km = KMeans(n_clusters=2, random_state=42).fit(X_train)\n",
    "km_pred = km.predict(X_test)\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, random_state=42).fit(X_train)\n",
    "gmm_scores = gmm.score_samples(X_test)\n",
    "gmm_pred = (gmm_scores < np.percentile(gmm_scores, 21)).astype(int)\n",
    "\n",
    "nb = GaussianNB().fit(X_train, y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "\n",
    "pca_svd = PCA(n_components=0.95, svd_solver='full')\n",
    "X_train_pca = pca_svd.fit_transform(X_train)\n",
    "X_train_recon = pca_svd.inverse_transform(X_train_pca)\n",
    "recon_error_train = np.mean((X_train - X_train_recon)**2, axis=1)\n",
    "threshold = np.mean(recon_error_train) + 3 * np.std(recon_error_train)\n",
    "X_test_pca = pca_svd.transform(X_test)\n",
    "X_test_recon = pca_svd.inverse_transform(X_test_pca)\n",
    "recon_error_test = np.mean((X_test - X_test_recon)**2, axis=1)\n",
    "pca_pred = (recon_error_test > threshold).astype(int)\n",
    "\n",
    "iso = IsolationForest(contamination=0.21, random_state=42).fit(X_train)\n",
    "iso_pred = (iso.predict(X_test) == -1).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "models = {'K-means': km_pred, 'NB': nb_pred, 'PCA-SVD': pca_pred, 'GMM': gmm_pred, 'Isolation Forest': iso_pred}\n",
    "results = {}\n",
    "for name, pred in models.items():\n",
    "    results[name] = {\n",
    "        'Precision': precision_score(y_test, pred),\n",
    "        'Recall': recall_score(y_test, pred),\n",
    "        'Accuracy': accuracy_score(y_test, pred),\n",
    "        'F-score': f1_score(y_test, pred),\n",
    "        'G-mean': g_mean(y_test, pred)\n",
    "    }\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b971d",
   "metadata": {},
   "source": [
    "## Visualization (Optional)\n",
    "Add plots here, e.g., confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed52365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Example: Confusion matrix for NB\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, nb_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
